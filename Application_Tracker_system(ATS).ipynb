{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPKymuTT+rKP3qLNCxPI+NG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "import PyPDF2\n",
        "import csv\n",
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "\n",
        "job_description=input()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bfUZWdkygoLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    t = \"\"\n",
        "    with open(pdf_path, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
        "        for page_num in range(pdf_reader.numPages):\n",
        "            page = pdf_reader.getPage(page_num)\n",
        "            t += page.extractText()\n",
        "    return t\n",
        "\n",
        "# Function to convert text to CSV\n",
        "def convert_text_to_csv(text, csv_file):\n",
        "    with open(csv_file, 'w', newline='') as csv_file:\n",
        "        writer = csv.writer(csv_file)\n",
        "        for line in text.split('\\n'):\n",
        "            writer.writerow([line])\n",
        "\n",
        "def extract_text_from(path):\n",
        "  return extract_text(path)\n",
        "\n",
        "def extract_contact_number_from_resume(text):\n",
        "  contact_number = None\n",
        "\n",
        "    # Use regex pattern to find a potential contact number\n",
        "  pattern = r\"\\b(?:\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b\"\n",
        "  match = re.search(pattern, text)\n",
        "  if match:\n",
        "      contact_number = match.group()\n",
        "\n",
        "  return contact_number\n",
        "\n",
        "def extract_email_from_resume(text):\n",
        "  email = None\n",
        "\n",
        "    # Use regex pattern to find a potential email address\n",
        "  pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"\n",
        "  match = re.search(pattern, text)\n",
        "  if match:\n",
        "    email = match.group()\n",
        "\n",
        "  return email\n",
        "\n",
        "def extract_skills_from_resume(text, skills_list):\n",
        "  skills = []\n",
        "\n",
        "  for skill in skills_list:\n",
        "    pattern = r\"\\b{}\\b\".format(re.escape(skill))\n",
        "    match = re.search(pattern, text, re.IGNORECASE)\n",
        "    if match:\n",
        "      skills.append(skill)\n",
        "\n",
        "  return skills\n",
        "\n",
        "def extract_education_from_resume(text):\n",
        "  education = []\n",
        "\n",
        " # List of education keywords to match against\n",
        "  for keyword in word:\n",
        "    pattern = r\"(?i)\\b{}\\b\".format(re.escape(keyword))\n",
        "    match = re.search(pattern, text)\n",
        "    if match:\n",
        "          education.append(match.group())\n",
        "          return education\n",
        "\n",
        "def extract_name(resume_text):\n",
        "  name_regex = r\"[A-Z][a-z]+\\s[A-Z][a-z]+\"\n",
        "  name = re.search(name_regex, resume_text).group()\n",
        "  return name\n",
        "\n",
        "\n",
        "  if __name__ == '__main__':\n",
        "    extract_text_from_pdf('er/resume.pdf')\n",
        "    UpdatedResumeDataSet=convert_text_to_csv(t,'er/ResumeDataSet.csv')#Example Resume\n",
        "    contact=''\n",
        "    for resume_path in resume_paths:\n",
        "        resume += extract_text_from_pdf(resume_path)\n",
        "\n",
        "        print(\"Resume:\", resume_path)\n",
        "\n",
        "        name = extract_name(resume)\n",
        "        if name:\n",
        "            print(\"Name:\", name)\n",
        "        else:\n",
        "            print(\"Name not found\")\n",
        "\n",
        "        contact_number = extract_contact_number_from_resume(text)\n",
        "        if contact_number:\n",
        "            print(\"Contact Number:\", contact_number)\n",
        "        else:\n",
        "            print(\"Contact Number not found\")\n",
        "\n",
        "        email = extract_email_from_resume(text)\n",
        "        if email:\n",
        "            print(\"Email:\", email)\n",
        "        else:\n",
        "            print(\"Email not found\")\n",
        "\n",
        "        skills_list = []\n",
        "        extracted_skills = extract_skills_from_resume(text, skills_list)\n",
        "        if extracted_skills:\n",
        "            print(\"Skills:\", extracted_skills)\n",
        "        else:\n",
        "            print(\"No skills found\")\n",
        "\n",
        "        extracted_education = extract_education_from_resume(text)\n",
        "        if extracted_education:\n",
        "            print(\"Education:\", extracted_education)\n",
        "        else:\n",
        "            print(\"No education information found\")\n",
        "\n",
        "        print()\n",
        "\n"
      ],
      "metadata": {
        "id": "ciq-K9wMvbcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Candiate_CV(file):\n",
        "  dff = pd.read_csv('UpdatedResumeDataSet.csv')\n",
        "  dff['cleaned'] = dff['Resume'].apply(lambda x:Clean_file(x))\n",
        "  #getting the entire resume text\n",
        "  corpus=\" \"\n",
        "  for i in range(0,len(dff)):\n",
        "      corpus= corpus+ dff[\"cleaned\"][i]\n",
        "\n",
        "df=Candiate_CV('UpdatedResumeDataSet.csv')"
      ],
      "metadata": {
        "id": "21s6-2bQcWuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Clean_file(text):\n",
        "    # Remove punctuation and whitespace\n",
        "    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
        "    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
        "    resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n",
        "    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n",
        "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
        "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText)\n",
        "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
        "\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    return text.split()\n",
        "\n",
        "def encode_text(tokens):\n",
        "    # Create a vocabulary of unique tokens\n",
        "    vocabulary = set(tokens)\n",
        "\n",
        "    # Create a dictionary mapping each token to a unique integer index\n",
        "    token_to_index = {token: i for i, token in enumerate(vocabulary)}\n",
        "\n",
        "    # Encode the tokens into numerical representations\n",
        "    encoded_tokens = [token_to_index[token] for token in tokens]\n",
        "\n",
        "    return encoded_tokens\n"
      ],
      "metadata": {
        "id": "r-XtBJd3vw4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n",
        "#Tokenizing the text\n",
        "tokens = tokenizer.tokenize(corpus)\n",
        "len(tokens)\n",
        "words = []\n",
        "# Looping through the tokens and make them lower case\n",
        "for word in tokens:\n",
        "    words.append(word.lower())\n",
        "words[0:5]\n",
        "label = LabelEncoder()\n",
        "df['new_Category'] = label.fit_transform(df['Category'])\n",
        "df.head()\n",
        "\n",
        "# Vectorizing the cleaned columns\n",
        "text = df['cleaned'].values\n",
        "target = df['new_Category'].values\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    stop_words='english',\n",
        "    max_features=1500)\n",
        "word_vectorizer.fit(text)\n",
        "WordFeatures = word_vectorizer.transform(text)\n",
        "\n"
      ],
      "metadata": {
        "id": "Rf1VGJrtdgL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(WordFeatures, target, random_state=24, test_size=0.2)\n",
        "# Model Training\n",
        "model = OneVsRestClassifier(KNeighborsClassifier())\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "FgsTe5PuFu8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stop words are generally the most common words in a language.\n",
        "#English stop words from nltk.\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "words_new = []\n",
        "#Now we need to remove the stop words from the words variable\n",
        "#Appending to words_new all words that are in words but not in sw\n",
        "for word in words:\n",
        "    if word not in stopwords:\n",
        "        words_new.append(word)\n",
        "\n",
        "# Lemmatization\n",
        "wn = WordNetLemmatizer()\n",
        "lem_words=[]\n",
        "for word in words_new:\n",
        "    word=wn.lemmatize(word)\n",
        "    lem_words.append(word)\n",
        "\n",
        "same=0\n",
        "diff=0\n",
        "for i in range(0,1832):\n",
        "    if(lem_words[i]==words_new[i]):\n",
        "        same=same+1\n",
        "    elif(lem_words[i]!=words_new[i]):\n",
        "        diff=diff+1\n",
        "\n"
      ],
      "metadata": {
        "id": "7PpQCVMiQvMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_job_description(job_description, corpus):\n",
        "    # Preprocess the job description and resume\n",
        "    job_description_tokens = preprocess_text(job_description)\n",
        "    resume_tokens = preprocess_text(corpus)\n",
        "\n",
        "    # Convert the job description and resume tokens to numerical representations\n",
        "    job_description_embedding = encode_text(job_description_tokens)\n",
        "    resume_embedding = encode_text(resume_tokens)\n",
        "\n",
        "    # Calculate the cosine similarity between the job description and resume embeddings\n",
        "    similarity = tf.keras.backend.dot(job_description_embedding, resume_embedding)\n",
        "\n",
        "    # Scale the similarity score to a range of 0 to 1\n",
        "    score_22 = tf.math.sigmoid(similarity)\n",
        "\n",
        "    return score_22.numpy()\n",
        "score_2= score_job_description(job_description, corpus)\n",
        "\n",
        "# Load the Universal Sentence Encoder model\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "embed = hub.load(module_url)\n",
        "\n",
        "# Define a function to compute the cosine similarity between two vectors\n",
        "def cosine_similarity(vector_a, vector_b):\n",
        "    dot_product = np.dot(vector_a, vector_b)\n",
        "    norm_a = np.linalg.norm(vector_a)\n",
        "    norm_b = np.linalg.norm(vector_b)\n",
        "    similarity = dot_product / (norm_a * norm_b)\n",
        "    return similarity\n",
        "\n",
        "# Define a function to score job description with respect to a resume\n",
        "def score_job_description_with_resume(job_description, corpus):\n",
        "    # Encode job description and resume using the USE model\n",
        "    job_description_vec = embed([job_description])[0]\n",
        "    resume_vec = embed([corpus])[0]\n",
        "\n",
        "    # Compute the cosine similarity between the two vectors\n",
        "    similarity_score = cosine_similarity(job_description_vec, text)\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "score = score_job_description_with_resume(job_description, corpus)\n",
        "\n",
        "result=int((0.63*score)+(0.37*score_2)*100)\n",
        "if result > 80:\n",
        "  # Create the email message\n",
        "  msg = MIMEMultipart()\n",
        "  msg['From'] = sender_email\n",
        "  msg['To'] = email\n",
        "  msg['Subject'] = subject\n",
        "  msg.attach(MIMEText(message_1, 'plain'))\n",
        "  try:\n",
        "      server = smtplib.SMTP('smtp.gmail.com', 587)  # Use the SMTP server and port for your email provider\n",
        "      server.starttls()  # Enable TLS encryption\n",
        "      server.login(sender_email, sender_password)  # Login to your email account\n",
        "\n",
        "      # Send the email\n",
        "      server.sendmail(sender_email, receiver_email, msg.as_string())\n",
        "\n",
        "      # Close the connection to the SMTP server\n",
        "      server.quit()\n",
        "\n",
        "      print(\"Email sent successfully to\", receiver_email)\n",
        "  except Exception as e:\n",
        "      print(\"Error sending email:\", str(e))\n",
        "else:\n",
        "    # Create the email message\n",
        "    msg = MIMEMultipart()\n",
        "    msg['From'] = sender_email\n",
        "    msg['To'] = email\n",
        "    msg['Subject'] = subject\n",
        "    msg.attach(MIMEText(message_2, 'plain'))\n",
        "    try:\n",
        "        server = smtplib.SMTP('smtp.gmail.com', 587)  # Use the SMTP server and port for your email provider\n",
        "        server.starttls()  # Enable TLS encryption\n",
        "        server.login(sender_email, sender_password)  # Login to your email account\n",
        "\n",
        "        # Send the email\n",
        "        server.sendmail(sender_email, receiver_email, msg.as_string())\n",
        "\n",
        "        # Close the connection to the SMTP server\n",
        "        server.quit()\n",
        "\n",
        "        print(\"Email sent successfully to\", receiver_email)\n",
        "    except Exception as e:\n",
        "        print(\"Error sending email:\", str(e))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I2_uOXpBr1uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "# Email configuration\n",
        "sender_email = 'your_email@gmail.com'  # Your Gmail email address\n",
        "sender_password = 'your_password'  # Your Gmail password\n",
        "  # The recipient's email address\n",
        "subject = 'Your Job Application Status'\n",
        "message_1 = 'Congratulations!You are selected'\n",
        "message_2 = 'Sorry,You are not selected'\n",
        "\n",
        "# Create the email message\n",
        "msg = MIMEMultipart()\n",
        "msg['From'] = sender_email\n",
        "msg['To'] = email\n",
        "msg['Subject'] = subject\n",
        "msg.attach(MIMEText(message, 'plain'))\n",
        "\n",
        "# Establish a connection to the SMTP server (Gmail in this example)\n",
        "try:\n",
        "    server = smtplib.SMTP('smtp.gmail.com', 587)  # Use the SMTP server and port for your email provider\n",
        "    server.starttls()  # Enable TLS encryption\n",
        "    server.login(sender_email, sender_password)  # Login to your email account\n",
        "\n",
        "    # Send the email\n",
        "    server.sendmail(sender_email, receiver_email, msg.as_string())\n",
        "\n",
        "    # Close the connection to the SMTP server\n",
        "    server.quit()\n",
        "\n",
        "    print(\"Email sent successfully to\", receiver_email)\n",
        "except Exception as e:\n",
        "    print(\"Error sending email:\", str(e))\n"
      ],
      "metadata": {
        "id": "SIrnn1t8zvMT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}